Training configuration: Namespace(seed=777, batch_size=128, lr=0.0005, weight_decay=0.0001, nhid=128, pooling_ratio=0.5, dropout_ratio=0.5, dataset='NCI1', epochs=100000, patience=50, pooling_layer_type='GCNConv', ablation=3, device='cuda:0', num_classes=2, num_features=37)
Epoch 0: Validation loss: 0.6936207838592158	accuracy: 0.4793187347931874
Epoch 1: Validation loss: 0.6923924559804355	accuracy: 0.49148418491484186
Epoch 2: Validation loss: 0.690059754680253	accuracy: 0.5912408759124088
Epoch 3: Validation loss: 0.684246731500556	accuracy: 0.6058394160583942
Epoch 4: Validation loss: 0.677516357161993	accuracy: 0.6180048661800487
Epoch 5: Validation loss: 0.6725089637032391	accuracy: 0.6374695863746959
Epoch 6: Validation loss: 0.6869823845633625	accuracy: 0.5279805352798054
Epoch 7: Validation loss: 0.6507143266589682	accuracy: 0.6228710462287105
Epoch 8: Validation loss: 0.6347863784381653	accuracy: 0.6715328467153284
Epoch 9: Validation loss: 0.6224173942621607	accuracy: 0.681265206812652
Epoch 10: Validation loss: 0.6103584238502521	accuracy: 0.6763990267639902
Epoch 11: Validation loss: 0.6183555120389247	accuracy: 0.6788321167883211
Epoch 12: Validation loss: 0.5937825595085349	accuracy: 0.6885644768856448
Epoch 13: Validation loss: 0.5888666282895128	accuracy: 0.681265206812652
Epoch 14: Validation loss: 0.5840694469256993	accuracy: 0.6788321167883211
Epoch 15: Validation loss: 0.584324124375689	accuracy: 0.6763990267639902
Epoch 16: Validation loss: 0.598034299493126	accuracy: 0.6958637469586375
Epoch 17: Validation loss: 0.5734876066518816	accuracy: 0.6861313868613139
Epoch 18: Validation loss: 0.575185058760817	accuracy: 0.708029197080292
Epoch 19: Validation loss: 0.5763126614610065	accuracy: 0.6958637469586375
Epoch 20: Validation loss: 0.5822248482066059	accuracy: 0.6861313868613139
Epoch 21: Validation loss: 0.5766360127432792	accuracy: 0.683698296836983
Epoch 22: Validation loss: 0.5712648192171342	accuracy: 0.681265206812652
Epoch 23: Validation loss: 0.572000672927448	accuracy: 0.681265206812652
Epoch 24: Validation loss: 0.5743093374581812	accuracy: 0.6861313868613139
Epoch 25: Validation loss: 0.5693250990261997	accuracy: 0.6909975669099757
Epoch 26: Validation loss: 0.5963365921428894	accuracy: 0.681265206812652
Epoch 27: Validation loss: 0.5769182423315489	accuracy: 0.6958637469586375
Epoch 28: Validation loss: 0.585773546910344	accuracy: 0.683698296836983
Epoch 29: Validation loss: 0.5778992831561978	accuracy: 0.6885644768856448
Epoch 30: Validation loss: 0.573411287182439	accuracy: 0.6958637469586375
Epoch 31: Validation loss: 0.5923368031671158	accuracy: 0.6861313868613139
Epoch 32: Validation loss: 0.585609050852829	accuracy: 0.6958637469586375
Epoch 33: Validation loss: 0.5775705648454726	accuracy: 0.6982968369829684
Epoch 34: Validation loss: 0.5785072470523435	accuracy: 0.6885644768856448
Epoch 35: Validation loss: 0.5966840915726339	accuracy: 0.6739659367396593
Epoch 36: Validation loss: 0.5841866838961042	accuracy: 0.7226277372262774
Epoch 37: Validation loss: 0.5732696468232612	accuracy: 0.708029197080292
Epoch 38: Validation loss: 0.5612902606490755	accuracy: 0.7007299270072993
Epoch 39: Validation loss: 0.5644546750108111	accuracy: 0.7153284671532847
Epoch 40: Validation loss: 0.5616576944244459	accuracy: 0.7128953771289538
Epoch 41: Validation loss: 0.5639226268387769	accuracy: 0.7201946472019465
Epoch 42: Validation loss: 0.5588719537368366	accuracy: 0.7201946472019465
Epoch 43: Validation loss: 0.5534227375856571	accuracy: 0.7250608272506083
Epoch 44: Validation loss: 0.556511853443155	accuracy: 0.7031630170316302
Epoch 45: Validation loss: 0.5580957138915421	accuracy: 0.7226277372262774
Epoch 46: Validation loss: 0.5633187305608225	accuracy: 0.708029197080292
Epoch 47: Validation loss: 0.6038253719209175	accuracy: 0.6520681265206812
Epoch 48: Validation loss: 0.565929194726503	accuracy: 0.7201946472019465
Epoch 49: Validation loss: 0.5569897440518196	accuracy: 0.7201946472019465
Epoch 50: Validation loss: 0.5476576162370742	accuracy: 0.7250608272506083
Epoch 51: Validation loss: 0.5398120787311934	accuracy: 0.7201946472019465
Epoch 52: Validation loss: 0.5426640382938431	accuracy: 0.7347931873479319
Epoch 53: Validation loss: 0.543999850604946	accuracy: 0.7055961070559611
Epoch 54: Validation loss: 0.536803660891642	accuracy: 0.7299270072992701
Epoch 55: Validation loss: 0.5546334723776565	accuracy: 0.7055961070559611
Epoch 56: Validation loss: 0.5591073326240781	accuracy: 0.7201946472019465
Epoch 57: Validation loss: 0.616323800562652	accuracy: 0.6472019464720195
Epoch 58: Validation loss: 0.6893437517820483	accuracy: 0.5352798053527981
Epoch 59: Validation loss: 0.6934924206884528	accuracy: 0.5158150851581509
Epoch 60: Validation loss: 0.6815547200595086	accuracy: 0.5644768856447688
Epoch 61: Validation loss: 0.679215795512327	accuracy: 0.583941605839416
Epoch 62: Validation loss: 0.6766996499685766	accuracy: 0.5888077858880778
Epoch 63: Validation loss: 0.6762233464967305	accuracy: 0.559610705596107
Epoch 64: Validation loss: 0.6733231880949071	accuracy: 0.6155717761557178
Epoch 65: Validation loss: 0.6636535616686744	accuracy: 0.5936739659367397
Epoch 66: Validation loss: 0.663707454709241	accuracy: 0.6228710462287105
Epoch 67: Validation loss: 0.664606340320151	accuracy: 0.6155717761557178
Epoch 68: Validation loss: 0.657287458433722	accuracy: 0.6228710462287105
Epoch 69: Validation loss: 0.658061637785603	accuracy: 0.6204379562043796
Epoch 70: Validation loss: 0.6562072447616688	accuracy: 0.6423357664233577
Epoch 71: Validation loss: 0.6480223291401735	accuracy: 0.6301703163017032
Epoch 72: Validation loss: 0.6548810063197374	accuracy: 0.6180048661800487
Epoch 73: Validation loss: 0.6498801609605478	accuracy: 0.6277372262773723
Epoch 74: Validation loss: 0.6499879238379263	accuracy: 0.635036496350365
Epoch 75: Validation loss: 0.6577607593397155	accuracy: 0.6228710462287105
Epoch 76: Validation loss: 0.6643792544548239	accuracy: 0.6082725060827251
Epoch 77: Validation loss: 0.6460123595820146	accuracy: 0.6180048661800487
Epoch 78: Validation loss: 0.6609329771241422	accuracy: 0.6180048661800487
Epoch 79: Validation loss: 0.6528262651169677	accuracy: 0.6180048661800487
Epoch 80: Validation loss: 0.6605043341643619	accuracy: 0.6228710462287105
Epoch 81: Validation loss: 0.6500219683867592	accuracy: 0.610705596107056
Epoch 82: Validation loss: 0.6460545718524868	accuracy: 0.5863746958637469
Epoch 83: Validation loss: 0.6495545055454375	accuracy: 0.6155717761557178
Epoch 84: Validation loss: 0.6433881031045658	accuracy: 0.5863746958637469
Epoch 85: Validation loss: 0.6485201703370923	accuracy: 0.6155717761557178
Epoch 86: Validation loss: 0.6432446992600341	accuracy: 0.6180048661800487
Epoch 87: Validation loss: 0.6413367473296006	accuracy: 0.6034063260340633
Epoch 88: Validation loss: 0.6552495190696995	accuracy: 0.6155717761557178
Epoch 89: Validation loss: 0.6407127705223659	accuracy: 0.6082725060827251
Epoch 90: Validation loss: 0.6386139120208666	accuracy: 0.6180048661800487
Epoch 91: Validation loss: 0.6401215388537034	accuracy: 0.6326034063260341
Epoch 92: Validation loss: 0.632911765662423	accuracy: 0.6277372262773723
Epoch 93: Validation loss: 0.6421822271787917	accuracy: 0.6472019464720195
Epoch 94: Validation loss: 0.6406119966158902	accuracy: 0.656934306569343
Epoch 95: Validation loss: 0.6351981429868081	accuracy: 0.6228710462287105
Epoch 96: Validation loss: 0.631428043337634	accuracy: 0.6374695863746959
Epoch 97: Validation loss: 0.6399098556407177	accuracy: 0.6228710462287105
Epoch 98: Validation loss: 0.6279644954523611	accuracy: 0.635036496350365
Epoch 99: Validation loss: 0.6253770563724267	accuracy: 0.656934306569343
Epoch 100: Validation loss: 0.6329299945320817	accuracy: 0.6301703163017032
Epoch 101: Validation loss: 0.635715122640568	accuracy: 0.6204379562043796
Epoch 102: Validation loss: 0.6305150684068963	accuracy: 0.6204379562043796
Epoch 103: Validation loss: 0.6590416762080505	accuracy: 0.6423357664233577
Epoch 104: Validation loss: 0.6312664523902021	accuracy: 0.6496350364963503
Epoch 105: Validation loss: 0.6170813474631948	accuracy: 0.6399026763990268
Test accuracy: 0.6885644768856448
